# Content Analysis: Chris Eliasmith - How to Build a Brain (Vision Weekend Europe 2024)

## Overview

This talk by Chris Eliasmith presents SPAUN (Semantic Pointer Architecture Unified Network), a large-scale functional brain model that bridges neuroscience, cognitive science, and AI. Eliasmith discusses the evolution from SPAUN 1.0 (2012) to SPAUN 2.0 (2018) and outlines the vision for SPAUN 3.0, emphasizing how brain-inspired models can inform both neuroscience understanding and AI development.

**Speaker**: Chris Eliasmith
**Event**: Vision Weekend Europe 2024
**Video URL**: https://www.youtube.com/watch?v=HpWpDIEm_qs

---

## Key Findings

### 1. SPAUN: The World's Largest Functional Brain Model

**SPAUN 1.0 (2012)**
- **Scale**: 2.5 million neurons, 7.5 billion connections
- **Publication**: Featured in Science journal and book "How to Build a Brain" (Oxford)
- **Key Innovation**: Functional brain model that performs actual tasks (not just structural simulation)
- **Biological Accuracy**:
  - Correct variety of neurotransmitters
  - Mapped physiology and anatomy
  - Generates realistic neural spike patterns
- **Capabilities**: 8 different cognitive and perceptual tasks

**SPAUN 2.0 (2018)**
- **Scale**: 6 million neurons, 20 billion connections
- **Capabilities**: 12 different tasks (expanded from 8)
- **Significance**: Comparable scale to large language models of that era

> "The model that we built is called spawn uh it's the world's largest functional brain model or it was in 2012 when we first proposed it... it had about 2 and half million neurons 7.5 billion connections which was a lot in 2012 right bigger than most neural networks"

### 2. Multitask Cognitive Capabilities

**Low-Level Perceptual Tasks**
- **Image Recognition**: Recognizes and categorizes images (e.g., identifying monkeys)
- **Digit Recognition**: Performs MNIST-level digit classification
- **Motor Control**: Physically modeled arm with torque and muscle simulation
- **Working Memory**: Maintains and manipulates information in short-term memory

**High-Level Cognitive Tasks**
- **Raven's Progressive Matrices**: Performs fluid intelligence reasoning
  - Pattern recognition and inference
  - Never seen specific problems before (true generalization)
  - Comparable to human-level abstract reasoning

- **Instruction Following**: Complex multi-step mental operations
  - Example: "Imagine letter V, rotate B 90° counterclockwise, place on top, erase back of B = heart shape"
  - Combines pattern finding, question answering, and mathematical operations

> "this is a brain model so you know we can take data... we can compare the Dynamics of the spikes generated by the model to the Dynamics of spikes recorded from a rodent in the same part of the brain"

### 3. Neuroscience Validation and Insights

**Multi-Level Biological Realism**
- **Neural Dynamics**: Spike patterns match rodent recordings in ventral striatum
- **Behavioral Patterns**: Exhibits primacy and recency effects in memory (psychological phenomena)
- **Pharmacological Effects**: Simulates drug interventions at molecular level

**TTX Experiment - Sodium Channel Blockade**
- **Setup**: Applied TTX (sodium channel blocker) to SPAUN+ model during working memory task
- **Result**: Model remembered information (432) but forgot what task it was doing
- **Insight**: Mechanistic hypothesis linking molecular intervention to high-level cognitive disruption
- **Significance**: Unethical to test on humans, but provides testable predictions

> "what I like about this example you'd never ethically do this experiment to a human right but now we have a really clear mechanistic hypothesis about what the relationship between this low-level you know molecular intervention and a high level cognitive effect"

### 4. Task Control and Cognitive Architecture

**Flexible Task Switching**
- Single unified model performs all tasks without architectural changes
- System receives task instruction and configures internal routing
- 12 different tasks in SPAUN 2.0, including:
  - Image categorization
  - Digit recognition
  - Motor control
  - Working memory
  - Raven's matrices (fluid intelligence)
  - Instruction following

**Instruction Following as "Mental Gymnastics"**
Example sequence:
1. Find pattern in digits (3 follows 1, 4 follows 2 → pattern: +2)
2. Answer question: What was in second position? (7)
3. Apply pattern to list (adds 2 to each)
4. Apply pattern to answer (2 + 2 = 4)

> "in spawn 2.0 we now have 12 tasks as opposed to eight um and you'll notice that the very last one there is instruction following and of course that's a very general task"

### 5. Implications for AI and Technology

**Neuromorphic Computing**
- Eliasmith's techniques used to program "pretty much every neuromorphic chip available"
- Current challenge: Scaling neuromorphic hardware to run full SPAUN model
- Potential for massive energy efficiency gains

**Novel Algorithms Discovery**
- **Bold Claim**: Discovered new algorithm that "outperforms Transformers by a fairly significant margin"
- Brain-inspired approaches can lead to fundamentally different AI architectures
- Cross-fertilization between neuroscience and AI research

**AI as Process vs. Static Models**
- SPAUN models AI as continuous process in changing environments
- Contrast to LLMs which are trained once and deployed
- More aligned with biological cognition and reinforcement learning

> "discovering new algorithms so I had this great uh conversation over lunch about a new algorithm that we've discovered using these techniques which outperforms Transformers by a fairly significant margin"

**Neural Prosthetics**
- Understanding of neural code enables better brain-machine interfaces
- Techniques already used in monkey experiments
- Potential for human applications

### 6. Future Vision

**5-Year Horizon**
- **AI-Brain Model Cross-Fertilization**: Already happening in vision, starting in language
- **Commercial Applications**: First broad applications of brain-inspired technology
- **Language Research**: Using LLM techniques to understand brain's language processing

**10-Year Horizon**

**Embodied Brain Models**
- Scale to trillions of synapses, billions of neurons
- Deploy in robots running on minimal power
- Full sensorimotor integration in physical world

**Digital Twinning**
- Scan individual person or animal
- Tune model parameters to match specific individual
- Model acts as digital replica of that particular brain
- Applications in personalized medicine and neuroscience

> "10 years uh out you know looking at things like can we embody these large Brain models right so we get up to you know trillions of synapses uh billions of neurons and being able to put those in robots"

> "the other thing we want to do is take the more Health oriented route where we would want do something like digital twinning right so where you can scan a person uh or an animal and be able to tune all of the parameters in the model"

---

## Technical Architecture Highlights

### Computational Components
- **Primary Visual Cortex**: Processes visual input, generates spike trains
- **Working Memory Areas**: Maintains information across time
- **Motor System**: Converts plans to physical movements
- **Control System**: Coordinates task switching and execution

### Biological Fidelity Levels
1. **Molecular**: Ion channels, neurotransmitters (SPAUN+)
2. **Cellular**: Complex neuron models with realistic dynamics
3. **Circuit**: Anatomically accurate connectivity
4. **Systems**: Brain region interactions
5. **Behavioral**: Psychological phenomena (primacy/recency effects)

### Scale Comparison
- **SPAUN 1.0 (2012)**: 2.5M neurons, 7.5B connections
- **SPAUN 2.0 (2018)**: 6M neurons, 20B connections
- **SPAUN 3.0 (future)**: Trillions of synapses, billions of neurons
- **Human Brain**: ~86B neurons, ~100T synapses

---

## Key Differentiators from Current AI

1. **Functional Biology**: Not just structure, but actual task performance with biological constraints
2. **Unified Architecture**: Single model for perception, cognition, and motor control
3. **Continuous Processing**: Operates as ongoing process, not batch inference
4. **Multi-Level Validation**: Testable against neural data, behavioral data, and pharmacology
5. **Interpretability**: Can examine every detail of how behavior emerges
6. **Energy Efficiency**: Brain-inspired approaches for low-power computation

---

## Notable Quotes

> "it was functional right so it was a brain model that actually did something uh which you know is not all that common surprisingly"

> "the same exact model can do much more complicated tasks so here's a cognitive task... this is patterned after an intelligence test that tests fluid intelligence called Ravens Progressive matrices"

> "this shows that you know the same techniques and model can do low-level stuff but it can also do cognitive stuff"

> "thinking about AI as a process which is not what llms are right so this is thinking about them changing over time interacting with constantly changing environments"

---

## Research Methodology

Chris Eliasmith's approach integrates three fields:
1. **Neuroscience**: Neural spike patterns, anatomy, pharmacology
2. **Cognitive Science**: Behavioral tasks, psychological phenomena
3. **Computational Theory**: Algorithms, representations, learning

This multi-level approach enables:
- Validation at multiple scales (molecular → behavioral)
- Bidirectional insights (brain → AI, AI → brain)
- Testable mechanistic hypotheses
- Novel algorithm discovery

---

## Applications and Impact

### Current Applications
- Programming neuromorphic chips
- Neural prosthetics research (monkeys)
- Understanding brain function
- Algorithm development

### Future Applications
- Low-power AI in robotics
- Personalized brain models (digital twins)
- Drug testing and intervention modeling
- Brain-machine interfaces
- Cross-domain AI (perception + cognition + motor)

---

## Critical Insights

1. **Biological constraints drive innovation**: Working within brain-like constraints led to algorithms that outperform transformers in some domains

2. **Scale matters but isn't everything**: SPAUN 2.0 at 6M neurons demonstrates complex cognition, suggesting efficiency in biological architectures

3. **Unification is key**: Same substrate handles vision, memory, reasoning, and motor control - unlike specialized AI systems

4. **Process vs. Product**: Framing AI as continuous process rather than static model aligns better with biological intelligence

5. **Ethical research tool**: Brain models enable experiments impossible/unethical on humans, advancing neuroscience safely

6. **Commercial readiness**: Technology transitioning from research to applications within 5 years

---

## Questions for Further Exploration

1. What specific algorithm outperforms transformers, and in what domains?
2. How does SPAUN handle continual learning and catastrophic forgetting?
3. What are the computational requirements for SPAUN 2.0 vs. comparable LLMs?
4. How would digital twinning account for individual neural plasticity over time?
5. What are the limitations of current neuromorphic hardware for running SPAUN 3.0?
6. How does instruction following in SPAUN compare to few-shot learning in LLMs?

---

## Conclusion

Chris Eliasmith presents SPAUN as a bridge between neuroscience and AI, demonstrating that biologically-realistic brain models can:
- Perform complex cognitive tasks
- Provide mechanistic understanding of cognition
- Inspire novel AI algorithms
- Enable ethical neuroscience research
- Point toward future low-power, embodied AI

The progression from SPAUN 1.0 → 2.0 → 3.0 mirrors the scaling of deep learning, but with biological constraints that may lead to fundamentally different and potentially superior approaches. The 5-10 year vision of embodied brain models and digital twins suggests a paradigm shift from current AI architectures toward more brain-like, continuous, and energy-efficient systems.

Most provocatively, Eliasmith's claim of discovering algorithms that outperform transformers suggests that neuroscience-inspired approaches may offer competitive advantages in the race toward AGI, not just biological understanding.