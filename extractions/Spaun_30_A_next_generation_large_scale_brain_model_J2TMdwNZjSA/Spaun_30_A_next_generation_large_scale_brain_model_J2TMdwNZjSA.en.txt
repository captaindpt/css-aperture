**Transcript extracted from YouTube video**

Kind: captions
Language: en
Testing 56.
&gt;&gt; Thank you, Maya. Appreciate that. It's
great to be here. I think it's uh yeah,
really exciting to get a group of people
interested in both neuroscience and AI
together to talk about their favorite
things. So, um yeah, as Maya mentioned,
one of my favorite things is the spawn
model that came out of my lab quite a
long time ago. So, it was 2012 was when
the first paper on spawn came out. Uh
and we're now a couple of generations
past that original work. And today I'm
going to talk to you about what is
really a work in progress. So Spawn 3
has not been published and we will not
really be publishing it for a little
while, but I think it's fun to show
people what we're up to. Um, so in order
to connect to today's theme though, I
also want to talk about how that model,
which is really a brain model, is
related to uh techniques and methods in
AI. And I think these connections have
become sort of tighter over the years in
my lab actually uh as opposed to
anything else. So, I think we all know
that current AI is pretty impressive.
Um, it can do lots of things that nobody
would have expected 3 years ago for it
to be able to do, but it also has
limitations that we don't see in
biological intelligence. And so, seems
like that's a good opportunity
potentially to learn about how to
overcome those limitations or at least
understand them better. Some examples of
this are that you do not have sample
efficient learning a lot of the time in
AI models. uh the really big ones in
particular. Um so yeah, having the right
kinds of inductive biases as Zach has
kind of turned me on to in the last year
or so is really critical in order to
have the kinds of behaviors that we see
in biological intelligence. And you also
find in LLMs in particular a lot of
imprecise reasoning, right? So if you
try to get it to do uh simple math, what
we would consider simple math, you know,
I give you two three-digit numbers to
multiply together, you can sit down and
you can do that and you can do it
accurately and typically you're
following some kind of algorithm in your
cognitive uh sort of reasoning and that
gets you to the right answer. These
models don't seem to be able to do that
kind of thing, right? you can do lots of
work to try to get them to overcome
that, but they're just basically
generally bad at having some reliable
reasoning technique that they can apply
in the right sort of circumstances.
So, uh on the other side, you know, when
we're looking at models of biological
con uh cognition, one reason we want to
do that is because it can help us
potentially uncover principles that have
been missed in this more sort of
functional approach that you is typical
of AI. Uh so those principles might be
things like you know how do we induce
the right kind of inductive bias to get
more sample efficient learning. Um how
can we incorporate the right kinds of
representations and methods inside these
large language models in order to
improve the precision of the reasoning.
So today we're going to see two examples
of that uh of these things. And I've got
little stars in case I forget to mention
that I'm giving you one of the examples.
I've got stars beside those. Uh because
really what I'm doing in this talk today
is telling you about spawn 3, right? And
so it's not the intent of spawn 3 isn't
really to uh sort of overcome these
limitations of AI, but I think it is
kind of let lets us move in that
direction in the ways that I just
described. So just to give you a sense
of sort of how my lab works and where
these large brain models fit into our
work, uh essentially what's happened
since the publication of spawn one is
that every six years or so, we put
together all of the new models and
methods and techniques that different
individual students or posttos have been
working on in the lab. Uh so a big
integrated model is kind of not one
person's job. It's more like you know a
student will pick a per particular area
they're interested in. They might be
interested in navigation or they might
be interested in motor control or vision
or something learning what have you and
they'll really work on a specific uh
sort of solution to that problem or
trying to get more insights in that
particular area. And then uh after you
know a lot of people have done that over
six years or so we were like okay let's
take everything that people have done
and see how much of that we can put
together. The idea being that you know
the whole is greater than the sum of its
parts right you can start asking
questions getting insights that you
can't get when you just look at
individual models. So, as I mentioned,
Spawn 1 came out in 2012. Uh, Spawn 2
came out in 2018. Uh, and what we've
been doing since then, I've been
focusing on a couple of core theoretical
issues. Um, which I think you can
generally think of as understanding how
to represent continuity uh in a way that
brains seem to. And this makes us think
about things like representing
continuous space. So, how do you have
maps where you can have features located
at any point throughout a map? Um so you
know a lot of modeling we worry about
having sort of structures which are sort
of like strict orderings or tree like
relations and so on. Um but you know
maps is something that brains are
particularly good at. Uh and we know
we've always been working on this if
people have heard about place cells grid
cells and so on in the hypocampus that
you know you know that those kinds of
representations are in the brain. Um but
having a really nice sort of theoretical
understanding of where they might come
from I think it's been missing. Same
thing in time. So time cells also in the
hippocampus uh discovered in like 2014
and people started thinking about you
know representations over continuous
time like over some window or some
period being something that brains
naturally generate and they're very good
at uh working with the sort of intuitive
way of understanding this as being new
is that if you're familiar with working
memory literature uh you know the
typical way that you test working memory
is you give people a list of items and
then you get them to repeat that list
back and you can basically say repeat
them back in the order I gave them to
you or just repeat them back in whatever
order you want to, right? So that's free
recall and serial recall. So what have
you imposed on people and giving them
this as a working memory task? Basically
that the order matters and this is all
you would test, right? You'd say like,
oh, here's the order. This is how many
people get right when it's halfway
through the list or if it's at the
beginning of the list and the end of the
list. So everything is very discretized,
right? You have basically slots. You
have things that the order is the all
that matters. Um, and if people do the
task, then you know, you think, okay,
now I've got an understanding of working
memory. But if you think about your own
working memory, it's temporal, right? So
you don't you do care about the order
things happen in, but you also know how
far apart they were in time, right? So
if you think about you went had lunch,
you spent a certain amount of uh time
in. So you know the order, right? You
went, you lined up, you picked up your
stuff, you sat down, you ate, you had a
conversation. So that's the order. But
each of those took a certain length of
time. And if you recollect that, you can
give very accurate uh descriptions of
how long those things took, right? And
so in the psychological literature,
there's kind of a sub field where they
look at timing and they distinguish
between retrospective and prospective
timing. And you can show that people
are, you know, quite good at estimating
intervals of time and all these sorts of
things. But most of our models are not
good at that, right? The models have
generally been constructed to be able to
maybe well definitely capture that
things are remembered but then maybe
capture the order in which they're
remembered but generally not capture the
information about how long did that
event take compared to the other events
or how long apart were those different
events. So so I think you know
intuitively brains are very adept at
representing information over continuous
time and being able to report on it but
a lot of our models haven't been. So
also important so time and space and
then uncertainty which is actually the
one I'm going to talk the least about
today. Um but if you're essentially
representing things over a continuous
space then you can think of a
probability density function as a kind
of continuous representation of
uncertainty. You also have discrete
representations of uncertainty and I'll
just leave it as a talk to me after that
the same representations we can use over
space and time can be used for doing uh
uncertainty representation.
So today what I'm going to do is briefly
talk about some of the general
techniques that we use to address these
issues but more generally build large
scale brain models. Uh and then I'm
going to tell you about some of the
early versions of spawn just to give you
a sense of like where we we're starting
from. Then I'll give you an update on a
current work in progress for spawn 3. uh
and I'll during that give you an example
of integrating spawn-like methods into
an LLM to show how we can improve the
representation or the performance of the
LM of particular types of tasks. All
right. And I'm also happy for people to
if they have a clarifying question just
to interrupt so I can address it right
away. Um but anything more substantial
please save. Okay. So back uh many years
ago in like 2003 Charlie Anderson and I
published this book called Neural
Engineering. And this forms the set of
techniques that even to this day all we
generally use in building these large
scale brain models. Uh we think of this
as a kind of neural compiler. So uh it
lets you specify some highle function
right. Uh so typically we like people to
specify those in terms of a dynamical
system. So you write down a differential
equation of some kind. So if you're
doing working memory could write down
the differential equation dxdt equals z.
Right? So whatever I stick in the memory
just stays there. Doesn't change over
time. That's a memory. Uh and then these
methods let you build a spiking neural
network that will uh approximate those
dynamics in neurons.
So we talk about three principles. Talk
about the principle of representation
which you can just think of like
highdimensional vector representations.
Talk about computation. So taking those
representations being able to compute
some nonlinear function of them. And
then the principle of dynamics. How do
you take high level dynamics and embed
them into sort of kind of neurally
constrained dynamics? Right? So neurons
and neural connections have particular
dynamics that we measure and are very
familiar with and they're determined by
things like neurotransmitters and so on.
How do we keep those constraints in mind
while implementing a dynamical system
performing some computation over some
representation? So you know what those
principles let us do essentially is take
any thing that you formulate in this way
and that's your high level language um
and then build a spiking network that
implements those dynamics like I said.
So this can be very useful for building
neural controllers or memories or um
decision-m systems like you know I think
pretty much everything the brain does
can kind of be written this way. So
ideally this is a very general technique
um and it lets us do this kind of
compilation
and what this helps us do is represent
or answer the question how does the
brain compute right so if somebody said
how does the brain compute I'm like
here's and we call this a zeroth order
guess just so you know we don't think
we've solved all the problems here but
you know we think it gets you in the
right direction how brains compute um of
course that doesn't tell you what brains
compute right so if you know the
function that brains are computing then
this might be a way of generating a
spiky network that you can compare to
the real spiky network and see you know
did we get the mechanisms and the
dynamics right potentially. Uh so the
second question is what does the brain
compute? Um and so the very first spawn
model was actually the seventh chapter
of this book. Um so this book came out
in 2013. So we published the paper in
science first and then published a kind
of booklength uh sort of discussion of
what the architecture was, how it was
built and all these kinds of things. And
there's a bunch of philosophy and stuff
in there as well. Uh but the point of
this was to basically say you know what
is the architecture that we think is a
reasonable one to capture what mamleian
brains do how they're organized what the
key components are and so on. Uh and so
this let us build this big brain model.
Uh the version two has about six million
neurons in it uh which turns into about
20 billion connections. So you know at
the time it came out it was I think the
largest but you know definitely one of
the largest neural networks artificial
neural networks anyone had built. Um and
I think it remains the largest recurrent
neural network. Right? So most of the
big ones that you hear about, they're
feed forward. This is definitely not
feed forward, right? It's very
recurrent. Uh in the model, you know, we
have lots of or four different types of
neurotransmitters. Uh we have an
anatomical and physiological mappings
between the components of the brain and
the uh components in the model. Um
they're matched. So you know the you
have the right types of activities and
things uh and neurotransmitters in the
right types of areas. Uh and the most
important thing for us is that it's
functional, right? So there have been
other large scale brain models, but they
typically don't sort of control a body
or execute a task, right? They've often
just been very big simulations.
So in spawn 2, that functionality
basically we described in terms of 12
different tasks. There's a bunch of
them. Uh I'm not going to go through all
of these in detail, but part of the
point was to show that, you know, the
model doesn't change between performing
any of these tasks, right? you just tell
it which task you want it to perform and
it goes and it does that task. Um, and
so you give it input and it will process
the input and so you does things like
counting. It does all kinds of stuff. So
I'll get I'll give you a couple examples
of those.
So uh, right. So here's the model. Uh,
you can see it's seeing images. It's got
one eye fixed. It's got a single arm.
It's controlling its arm with these
muscles. Um, what it's doing at the
beginning here is it's basically writing
down a one if the two images are from
the same category and a zero if they're
from different categories. Um, and now
it's just drawing out whatever digit it
sees. So, we're showing it different
images. And so, it's kind of doing a
classification plus a drawing task at
the same time. Um, it will uh, you know,
let us because I right as as you
mentioned, because it's an artificial
neural network, we have access to all
the data, right? There's no missing data
here. We can look at all the spike
trains, every spike time, everything.
Um, and so, you know, we can record
everything that's going on in what V1 of
our brain model is. And then you can
also see the decoding of the V1, right?
But you'll notice that in order to
perform this writing task, that's not
enough, right? You have to not only know
what digit you saw, but you have to
remember that over some length of time.
So, you can see in more frontal areas,
you've got something like a working
memory where it will stick around for
some length of time. And then that
information is given to a motor system
which is basically plotting a set of
points in a 2D space which is then
projected into a sixdimensional space to
control uh the activities in these
muscles which generate torqus on the
joints and let it draw things out. So
the nice thing about this is that you
know you have you can do exactly this
task in monkeys and humans uh and in the
model same exact inputs same outputs
same analyses you can go and you know
analyze these with whatever your
favorite sort of spike time method is
and and all that kind of stuff as well
as look at the behavior right how long
did things take to respond what happens
when you do different kinds of uh
perturbations or damage of the networks
in different ways and so on
so you know That that's a nice sort of
simple example. One thing I did want to
show is just that, you know, the the
visual system uh like it can't draw
complicated things, but it actually can
do uh essentially you know
classification over about a thousand
different categories. And so this is
kind of like the internal uh full model
through the vententral stream of the
model. And you can see interesting
things like you see increased
sparification over time and other sorts
of things that you know are uh
properties of what we think the way
visual processing works. You see make
mistakes. Um but you can see that you
know it's doing some sort of fairly
interesting visual task. It's actually
executing a function and it's doing this
all in spikes. So we can take that data
and we can do an analysis on it that
looks like the same as the analysis we
do on monkey data. Right? So here's an
example where we've shown a bunch of the
same images to the model that were being
shown to monkeys. We then took the same
analysis method that they used in the
paper where you're basically doing some
kind of analysis on the timing uh of
spikes given the sorts of inputs that
you're providing and then see that we
find you know very similar tuning in
individual neurons. Uh and the relevant
thing here is that usually if people
look into a vision model and they plot
these what they're plotting is weights,
right? And that's actually a thing that
you cannot measure very easily from
animals. Uh and so typically you're
generating the plots in kind of
different ways and you could worry about
whether that's telling you the same
information. Uh but in a case where
we've got all of the spike timing etc
then you know that the method for doing
the data analysis is not going to be
changing between the two instances.
uh we can look at things that are kind
of more dynamic. So this is a uh a
bandit task. So basically, you know,
rodents are walking up to a decision
point and then deciding to go left or
right. And there's reward with some
probability on either side and you can
switch the reward probability. Uh and so
they learn over time. It's a
reinforcement learning task. Learn over
time which way is going to give them the
most reward. Uh and here we have the
model doing the same thing. Uh in the
case of the model, it's not walking
through an environment. It's being shown
digits one or zero with different
probabilities. and then it has to you
know pick which digit is basically or it
has to guess which digit is the most
rewarded and when it writes a digit out
it will get a a reward etc. Anyway so
what you can see though is that you've
got you know very similar sorts of
dynamics over the delay approach reward
and return segments of the experiment
which the original experimentalists had
identified. Um and you can do again the
same sort of analysis
um to find that you have a lot of the
same kind of uh sort of dynamics of the
neurons over time. And again you you can
plot all the spikes both from the rodent
and from the model. Uh and you know
maybe there's an issue here with your
model. Maybe something needs to be
improved in order to uh fix that.
Although it's hard to tell because we
don't have confidence intervals
fortunately from the original
experimental data. But that gives you
kind these are just like different types
of analyses you can get out of this
large scale model. Um but then of course
the other thing we wanted to make sure
that it was really a cognitive model. So
it was doing things that essentially
humans do and most other animals don't.
So this is an example of that. So this
is patterned after the Ravens
progressive matrices intelligence test.
So you're supposed to figure out what
goes on there at the end. Uh and so you
as a human probably have no problem
doing this task. Uh and so we can watch
the model do the same thing.
Now there's some key differences like we
have to present everything in one place
because the model doesn't move its eye
around. So it's being shown these
triangles to basically indicate when a
particular uh element in the matrix has
been completed. Um but you know it's
just like you it's kind of never seen
this before. So it has to figure out the
pattern by seeing it the first time and
figuring out what sort of explains the
change over time. And then when we get
at the end, it writes out the right
answer, which is presumably the answer
that you got. We can perform this task
on like a bunch of ravens progressive
matrices and show that it gets about the
same. It's a subset of the full ravens.
Um, but show that it gets like the same
accuracy on that subset as humans do,
college educated students, I guess, is
the direct actual comparison. Uh but the
idea being that you know this same model
is now able to do motor control,
decision-m uh perceptual cognitive
tasks, right? All inside the same model.
Uh and then the last thing I'm going to
show is what we like to call mental
gymnastics. Um because this is
essentially taking a bunch of the skills
that the model has and putting them
together. So it's also called
instruction following. Um so just to
give you a sense of this, uh I'll get
you to follow the following instructions
and see what you come up with. Um, and
it's analogous to what we think the
model is doing. So, imagine the letter
V, capital letter V. Imagine a capital
B, and rotate it 90 degrees
counterclockwise.
And then put it on top of the V and
erase the back of the B. And what shape
do you have?
&gt;&gt; B. Back of the B. Yeah.
Yeah. What did you say? a three if you
just Yeah.
But you So you have to take a V, you put
the So we got the answer here. Anybody
else get the Yeah. Yeah. Exactly. So
yeah, you take the V, you put a B on top
on the back of it and erase the back,
right? So you have this heart shape,
right? Some people call it a two scoop
ice cream cone shape, too, which I guess
I can see. Uh but in any case, so what
what you were doing, right, is you were
generating internal mental
representations. You were manipulating
them in particular ways. you were
associating them with each other and
then generating a final answer. So the
same thing kind of thing is going on
here. Uh so this is basically doing
something like the Ravens matrix. So
it's trying to find a pattern in some
inputs that we're providing to it. Um
it's then going to do a question answer
task where we give it a bunch of input.
So it's like a working memory task. We
give it a list and then we ask it a
question about the list. Um
but it's going to the question is going
to be formulated in terms of the pattern
that was found here. Uh, and then we're
going to apply the pattern to the list.
And in this case, apply means add. So
basically, you know, if we find some
pattern like four, and we have some list
here, then we'd add four to whatever the
list is. So every item in the list would
be incremented by four and then you'd
have to say the answer out. And then
we're going to apply the pattern that we
found to the position we were asked
about, right? So kind of like asking
to take intermediate u mental
representations and combine them in some
interesting way. Uh so it goes by pretty
quick which is why I explained it in
advance but we can play it more than
once. So right so it's starting off and
it's basically saying what's the
relation that is between one and three
and also between two and four. So it's
increment by two. Um and here's a
question right what's at position two in
this list. So it writes out a seven. Uh
and then let's say apply the pattern to
the list. So the two so it writing it
six n and four. So it's adding two to
every item and then it's being asked to
apply the pattern that it found here to
the position. So it's adding the two and
the two and getting four, right?
Okay. So the the idea here is basically
it's following like this is a set of
instructions that's been loaded into its
working memory and then you're giving it
a bunch of input and you know it can
follow these for whatever input you give
it uh that's valid basically and if it's
invalid it just kind of stops and waits
until you give it valid input. Um, so
yeah, so it's an example of kind of, you
know, doing the sorts of things and and
we can't this is one task. So because
it's instruction following, you can kind
of get it to do many tasks. It will
follow instructions, but um, you know,
it's sort of an example of the most
complicated task I'd say that spawn 2
did.
All right. Um, so just to give you a
sort of bit more information about the
model, you know, here's an anatomical
view of the model. Uh, so you can see
sort of standard brain areas. So
posterior proto cortex motor areas and
one SMA. This is basil ganglia. So it's
actually subcortical uh visual system
anterior infratemporal phalamus also
subcortical etc. Right? So you've got
all of these different brain areas. Um
you know all of the connections that are
in the model are in the brain.
Unsurprisingly the converse is obviously
not true. Uh but we've got you know the
right kinds of connectivity going on
here. So these are all mo are mostly
inhibitory connections inside the basil
ganglia as you find in real basil
ganglia. You've got the you know
properties you've got like straightal D1
and D2 so different types of dopamine
etc.
Um you can also take this functional
perspective right so these colors it's
like this dotted orange line around
action selection right so that's a
function is the same dotted orange line
that was around the basil ganglia right
so you can see some of the mappings
between function and an anatomy in here
um but you can see that you know there's
no label of a task name in here this is
just a bunch of different information
processing combined in different ways to
perform the tasks that it performs right
so things like processing the visual
input and encoding it. Being able to
store information over time, being able
to take uh sort of output, decode it,
and then turn it into some sort of motor
command, uh being able to evaluate
rewards and update representations based
on rewards. And this is for uh transform
calculations for like inferring how two
inputs relate to one another like what
is the transform that gets you from one
to the other. So that's critical for
doing the Ravens progressive matrices.
uh so right so this is you know a
perspective which I think is important
that we we take the the kind of key
information processing components to be
important um and they're not really task
specific right it's more like what are
the things that brains need to do that
are then combined into doing all those
tasks and the combining part happens
basically through the basil ganglia
action selector right so it's monitoring
all this is all cortical right it's
monitoring cortex and all the different
kind of cortical states uh and depending
on those it will affect these what you
can think of gates. So it will basically
determine what information flows at some
point in the task into working memory,
right? Or into reward evaluation or into
information decoding, right? So it's
kind of controll controlling information
flow uh in order to perform those tasks.
Uh and it itself is actually not a
particularly large part of the model,
but it's playing this uh fairly
essential role.
Okay, so that's the original or the
second version of the spawn model. Uh
what are the shortcomings of the model?
There are many many many shortcomings.
It's 80,000 times smaller than a human
brain, right? So it's kind of tiny in
some ways. Uh one key one for us is that
it has no environment and body, right?
It's a disembodied eye staring at a
screen and an arm. Um clearly not a
great uh sort of model for most
biological systems. Um so really this is
kind of the key thing that we wanted to
address with the next version of Spawn,
right? We want to put it into a 3D
world, give it a body, make it do tasks
like navigation is the obvious thing
that you can do in a 3D world. Um, and
and related things like you can do yeah,
you know, uh, sort of scrging around
looking for different sorts of things.
Uh, and you can do working memory in a
3D environment and all that kind of
stuff. So that's really what we were
interested in.
uh another sort of key uh limit
limitation is that most of the highle
representations were discreet in the
previous model. So, you know, doing the
Ravens progressive matrices, you've got
digits which are discreet. You've got
some numbers of digits in each of those
different boxes, uh, which are discreet.
And, you know, it could kind of do
language- like processing, but again,
it's all very discreet. And as I was
arguing at the beginning, things like
maps, which of course, if you want to do
navigation, you have to have, um, are
much more continuous. And so even if you
just look at the kind of working memory
model
uh in the original spawn, it's kind of a
a model where you've got these virtual
slots and you can put items into the
into the slots. So you can put digits
into each slot uh and then you can
decode any slot. So when we were doing
the question answering, you know, what
was in slot number two, it could answer
that question. Okay. Um but it's not
really able to answer questions about
like how far apart in time were these
two or or any of those sorts of things.
So all the representations are kind of
discreet. Um so it's good for language
like uh representations ravens
regressive matrices and list memory but
bad for continuous maps. So in something
like the list memory you know you've got
basically a fixed number of or you don't
have a fixed number of slots but you've
got discrete slots. Each slot is its own
thing. Uh in a map you can think of a
map as having continuous slots right
like every every position in space there
could be a thing sitting there right at
every metric position. And so you should
be able to like put a a jug which is
sitting in the corner of the room at the
corner of the room or you should be able
to put the same jug kind of you know one
meter away from the door and etc. It
could be floating up somewhere right? It
should you should be able to kind of
have those features represented at any
location in the space.
Okay. So so these discrete
representations aren't aren't something
you want to get rid of, right? I think
they're key for uh language- like
structures. Um and in uh representing
them in the original model, we use
something called vector symbolic
algebbras and they have a couple of
operations which basically let you do
things like binding. So they let you
kind of like define a slot and then bind
a filler to the slot and then you can
have lots of slots and you can add them
all together. You can do similarity
operations to see which things are
similar to which other things. You can
unbind things from slots. Uh and so
interestingly those same operators can
actually be used to define continuous
slots in maps as well. Um and so this is
something that we've been working on
recently and we're introducing into
spawn 3 because we've got it working
really well for doing things like
navigation in uh and keeping doing path
integration and basically all the things
that animals seem to do. uh and we can
replicate things like place cells, grid
cells, time cells like all of these
sorts of things that you again find in
the hippocampus which are important for
continuous space and time representation
uh we can get using our uh vector
symbolic algebbras and related
techniques. Um so yeah so continuous
space representations we have some
publications on that. Uh we also have
work on continuous time representations.
uh this has actually turned into uh what
people in the AI literature know as
statebased models, right? So these are
kind of often touted as the next
generation of transformer. They're much
more efficient and so on. Uh and so we
published the first uh state space model
uh back in 2018 2019. Um and you know
that's also the kind of thing that is
really good at representing continuous
time because it's basically introducing
dynamics into neural networks. uh and we
can uh you know use those techniques for
doing things like introducing language
models potentially into a model like
spawn as well
uh right and these are from biology
right so this is as I was saying before
like you know one connection between AI
and biology in my mind is basically
state space models right that's where
they came out of looking at how time
cells can be modeled in the brain so on
to spawn three what are we what are we
doing in spawn three So uh you know so
far we have picked Isaac sim. So this is
a standard robotic simulator to be our
physics engine and our visualizer. So
you can see the body and see space and
all that kind of stuff. Uh we're using
Nango which is an open source package
that was first developed in the lab to
do all of our spiking neural network
simulation and and non-spiking. Uh the
first thing we looked at doing was
implementing SLAM. I guess I should also
say like one of the things we want to do
in spawn 3 is all of the stuff that
spawn 2 did plus more, right? Like we
don't want we don't want to kind of lose
any of the skill set. Um and so yeah,
I'm not going to talk about that, but
that is part of the goal. Um so instead
I'll focus on the new stuff. So in this
case doing simultaneous localization and
mapping um in a spiking network and be
able to, you know, put that into this
issim simulator.
Um that means that we're going to have
to have a better vision model. So it has
to do things like estimate depth in 3D
world and things that it didn't have to
do before. Uh we have to implement
control in the body. So we have to be
able to move around as well as control
the arm. So you know we have a good leg
up on the arm control but still have to
do walking and so on. Um we have we um
also have built a navigation based
spatial working memory experiment. So we
found a good working memory experiment
that had been done on humans which I'll
talk about shortly and replicated that
in the simulator. Uh, and here it is. Or
here here's our environment to start
with. So, this is a top down view. Um,
this is the thing that we call the
arcade, which you can see the little
agent standing there. The arcade has a
screen in it where the agent can stare
at it and basically do all of the
experiments that it did before. Um, it
was maybe I won't talk about that. It
was it was instructive. So, initially we
tried to take all of those experiments
we did on the screen and translate them
into 3D equivalents, but you cannot do
that, right? which gives us a I think is
very important to realize when you're
doing those kinds of experiments that's
what you're learning about right you're
not necessarily learning what it would
mean to then put that in the real world
and have people you know with a body
moving around in space etc um then we
also have this part of the environment
which is where you know we can move
around in 3D space and we're basically
replicating uh a working memory
experiment that people have done in
virtual reality and because you need to
do that in order to get brain data at
the same
our detailed brain data. All right. So,
yes. So, this is the, as I mentioned,
the arcade. Um, so this kind of looks
exactly the same as before and now it's
going to, you know, reproduce all of the
tasks that I've already talked about.
Um, this is the working memory
experiment. So, the way this works is
you put people in virtual reality. These
are all people who had MEG, so right on
cortex, basically doing hypocample
recordings. So, we can get like detailed
neural data from humans. Um, and
essentially what they were doing is they
were in this environment. They would
walk up to a a chest. The chest would
open when they got close enough and it
show them an item. So, this has an
hourglass in it. Uh, and then they would
be directed to go to the next one and
they would look in that box. And then
this has a bunch of wooden logs in it.
Um, then they would do a distractor task
where they have to kind of just, you
know, do the shell game. You got
something kind of hiding from you. And
then they're and then they're queried
about what they remember. So they're
asked do you remember where the wooden
logs are and you either say yes maybe or
no and then you're asked to indicate
where the they are and then you're given
feedback about you know did you get it
right or were you wrong and where was
where is where was it actually right so
it's kind of a standard working memory
task um you can see here over a bunch of
they had 43 I think or 46 different uh
patients and they got accuracy across
the task um they also looked at accuracy
as a function of the confidence reported
Um and uh yeah and the accuracy as a
function of the you can basically these
colors are matching on and you can see
how the confidence and accuracy are
related to one another again. Um and
then also important for our purposes is
we have you know hypocample data right
so they distinguish between left and
right hypocampus and they look at times
when it was a recalled object or not or
there was no item. Sometimes these are
empty right and so they also have a no
item condition. Um, and so that is what
we take ourselves uh to be trying to
replicate. We haven't done we haven't
replicated the details of the hypocample
data yet. We've got some intriguing
first passes, but I'm not going to show
you that. I'm going to mostly just focus
on behavior for now. Uh, so you know,
here this is a top- down view. Um, this
is the internal representation of the
agent, right? So this is going to be
like what does the agent remember as it
walks around through? And you can see
we've got all these boxes set up and
it's going to walk past the different
boxes and see different things. So this
is its first person view. Uh this is
where it's walking. And you can see
we've got the actual desired and
inferred paths. Inferred being where it
thinks it went. Uh and so here it's
coming up to the objects. These are a
little bit out of time. And then the box
is disappearing and then it's generating
a representation of the object being at
that spatial location. And you can see
over time that these drift a little bit,
but by the time it gets to the end, it's
kind of seen all of them. It's got some
representation of where they all were in
space. uh and then we can go and query
the agent and say like where did you
remember where was the banana right
uh we can also look at the activity in
the hippocampus of the model part of the
model uh and so here in entrano cortex
this is basically doing all of the where
am I right now right so this is all grid
cells basically activity um and CA2 is
when it's encountering a new thing in
the environment you can watch how the
activity changes when it's basically
saying oh there's an item there I'm
gonna have to remember for later um so
it's actually quite unfortunately. But
you know, there's a bunch of activity
going on here which is kind of slowly
moving around. And here you don't see a
lot of activity until it actually bumps
up into one of those objects and then
you'll see a kind of little burst of
activity in here. I hope. Yeah, there
you go. That was very brief. You can see
more subtlety in the uh in the version
on my laptop, but you get the you get
the idea, right? So this is the data
that we can now take and do sort of
filtering to compare to the neural data
that they recorded from the agents or
from the patients.
Right? So one thing that we want to make
sure is that we you know have the
low-level single cell data correct. Um
and so this is showing examples of
different types of cells that are in the
model. Right? In the gray in the
background is a sort of movement of an
agent throughout an environment. And
we've done comparisons. We've taken like
the same movement that you have on
rodents and uh demonstrated that you get
these effects there as well. So you can
see things like grid cells, right? And
you can see over more time the grid
cells become better defined. You have
things like object vector cells. So
these X's are where objects were and you
can see uh cells that are sort of firing
whenever the agent is within some
consistent egocentric relation to the
object. Um and you can also find place
cells where whenever the agent goes
through that place, there's activity of
a cell and so on.
Uh and then we can also compare the
behavioral level accuracy. Um so here
what we're doing is basically matching
the human and model recall accuracy. Uh
so this is the graph that I showed
before. Um and here is the accuracy in
the model. And the one thing that we're
changing basically is how uh how many
grid points are used by the agent to
decode its estimate of spatial location.
Um so you can see if you use a lot of
points so 50 you actually get extremely
good superhuman performance. like the
model is essentially never wrong. Um and
so in order to match the human data, we
basically had to decrease the sampling
of the um space in order to estimate
where the uh object that it had
encountered actually was. And you you
know in so doing you can find basic you
can find one particular or there's a
range of values but you know some values
which give you a pretty good match to
the accuracy behavioral accuracy that
you find in humans. Um, so you know this
for the time being is something of a
hypothesis about why do people and I
will say people do kind of badly at this
task, right? So they do worse than I
would have expected. Um, and this is one
hypothesis for what's going on, right?
Is that you you basically have a non
great representation in order to try to
do the decoding and to uh get your
estimate of where the thing you met was
in space. But I think this is an early
hypothesis and I think others will come
along as we make the model more
sophisticated.
Um, okay. So, that's kind of an example
of one of the things that we've done
with Spawn 3. Um, and that's really
trying to address like a new kind of
neuroscience data that we couldn't get
in earlier versions of the model. Uh,
this is more of a connection to methods
in AI. So, taking the representations
that we've got, so these vector symbolic
algebbras that we've got in spawn and
using them to improve the performance on
a large language model task. Uh so so
what we would uh you know one of the
thing we would like to do is add into
the model so we're still building it add
in a large language model uh you know a
statesbased model based one. Um but then
we also would like the reasoning in that
model to be more humanlike in the sense
of being able to accurately do things
like simple math problems. Uh so spawn
can do step by step step by step step
action execution right so you can
essentially give it in the in the basil
gang you can give it a kind of algorithm
and it can go through the steps in the
algorithm right we saw that in the uh
mental gymnastics task so we know we
have that kind of ability something
which you often are lacking in LLMs um
and so what we're going to do is rely on
that and use the same representations
we're using in spawn for doing
structured uh representation this vector
symbolic algebraas but try to introduce
those into an LLM and show that if you
have that and a stepping algorithm you
can get improved performance right so
that's kind of the the job we have for
us uh and I think this is going to be an
example of demonstrating that merging
bioinspired models with AI methods can
actually get you something that you
don't get alone
all right so here's what we did uh so we
tested this on math problems in
particular um so a math problem would be
something like what is 910 mod 213
uh and we need a representation of the
problem, right? So here's a vector
symbolic algebra representation of the
problem where this operator is a binding
operator. So it's basically saying my
hundred's digit is a nine. My 10's digit
is a one. My ones digit is a zero and
that's for the first number. So the
first number right is bound to that
representation. Second number is bound
to similar representation for the second
number and the type of problem that
we're doing. So the operator is modulo,
right? So this is the kind of
representation that once we have it we
know spawn can go through the steps
right and say oh if it's a module
problem then go through these steps take
this thing and do these manipulations
and so on. Um so what we did in the case
of the large language model is we took
the large language model and you know
stuck in just the uh sentence right of
course you you've turned it into uh
vector or embeddings and all these kinds
of things. So you've got the sentence
going in and then somewhere through the
language model, we basically took the
representation the language model had
generated. We then encoded it. So
basically taught it how to turn that its
representation here into this
representation. Uh then executed the
algorithm that we know will solve the
problem, generate a representation that
we could then stick back into the
language model, right? And sum it into
its representation and let it continue
on its way until it generated an answer.
Okay? So what we're essentially doing is
we're kind of going in and saying you
know once you know that this is an
algorithmic type problem math problem to
solve you just represent the input in
the right way you execute the algorithm
on it and then it gives you the right
answer right um so this symbolic
algorithm is the type of thing that we'd
like to be executable in spawn um in in
the original paper we're just doing it
in Python just to keep things simple uh
and more friendly to machine learning
audience uh and when you do that you
find a huge increase in performance.
Right? So what we're showing here is
like over all of these different math
tasks. The blue line is the performance
of the neurosyolic
uh language model. And then we have a
couple of other comparisons. So we have
the standard LLM in orange. Um we have a
Laura. So this is a fine-tuned version
of a large language model in red. So you
can see it does better on some things
but it also gets worse on other things.
Uh and then we have a chain of thought
method. So these are like the standard
method people try to use to get a
language model to actually reason
better. So then we have chain of thought
and again you can see it gets better at
some stuff but also worse at others. Um
another key thing here these two tasks
addition and integer division are things
that the language model already does
pretty well. Um and so we don't
intercept or we don't sort of encode it
in this way and try to get to do it
because it already does fine. So we just
let it do those problems the way it
already does. Um and this is showing
that when we do that we also don't hurt
the performance of the model right for
tasks that it already knows how to do.
Um so overall you know this is a you
know 73% higher absolute accuracy. So
it's not a 70 like 73% you know it went
from like 5% to 90% on bitwise exor and
so on. So huge huge improvements. Um and
so to me this is the kind of thing that
where you know what we did was basically
take this bio inpired type of
representation introduce it into a
language model and get a massive improve
improvement in reasoning on particular
task types. Uh and now we're looking at
you know generalizing it to more
challenging things than math and so on.
Um yeah so as I mentioned it's a work in
progress. So we also have a couple of
other sorts of next steps that we're
looking at. So, we're improving the
working and long-term memory to do
things like capturing, you know,
temporal distances between objects and
lists and so on. Uh, we also need to
tell it in the original spawn model, we
would show it the digits like say, you
know, A1 and then it would know which
task to do or A5. It's not in front of a
screen all the time anymore. So, in
order to tell it what to do, we're going
to give it an auditory system. So, we
just tell it what to do with words. Uh,
which is I don't know. So what I it's
these are hard decisions to make about
what to add into your model and what not
to but it seems like a pretty reasonable
thing to do. Animals are fairly good at
you know responding to verbal commands
and so on. So having an auditory system
uh that then lets you interpret the
input as a command seems like a fairly
reasonable thing to do. Um we are adding
a path planner. So right now when it was
doing the the memory task actually the
humans doing that memory task they're
told where to go. They don't have to
plan a path. So, it's kind of okay, but
ultimately we want it to do things like
foraging tasks as well. And so, it needs
to be able to plan paths. Um, so we're
working on that. Uh, maybe adding a
second camera for improved depth
estimation. It's it does okay with what
it has. So, that maybe a complexity we
don't need. Um, we could do things. We
have amydala models which would
introduce sort of more emotional
processing. So, getting like fear
conditioning and so on in there. So,
these are questions in our minds, right?
So, I'm always happy to hear people's
opinions about what would be the most
compelling things to add into a model
like this.
uh and yeah I just wanted to kind of
mention this as us seeing the
relationship between AI and uh neural
modeling large scale neural modeling
like we're doing as being a two-way
street right so we learn things from AI
for sure right it's like the surprising
impact of just scaling these really
datadriven methods right the kinds of
things that uh LLM have learned to do is
is really quite impressive um being able
to you know have useful starting
functional systems and being turn be
able to kind of turn them into something
which is bioplausible. Um so you know
right now I think our best models of the
visual system are basically deeple
learned models right uh so you we
definitely have exploited that kind of
thing in neuroscience. Um and then the
other way around right is that you have
often have surprising efficacy of
bioinspired either architectural or
representational constraints right so uh
so state space models are one example of
that. So introducing uh sort of like
dynamics that were not previously in
these models can be very useful. um
putting in architectural constraints
like just the way that you set up your
cognitive model in order to like figure
out when to use different components in
order to perform uh or perform a
specific task or in the case of
representation you know introducing
these VSA representations into the LM in
order to get it to perform better. Um
and then oh yeah and then these are kind
of those examples that I just mentioned.
Uh and yes, thank you for your attention
and I'm happy to take any questions.